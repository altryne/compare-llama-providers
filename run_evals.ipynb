{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare LLama Providers\n",
    "\n",
    "This notebook is designed to compare the outputs of different LLama 3.1 server providers. It uses Weights & Biases Weave Evaluations to analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "from tabulate import tabulate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Define the providers and their endpoints\n",
    "providers = {\n",
    "    \"Provider1\": \"https://api.provider1.com/llama\",\n",
    "    \"Provider2\": \"https://api.provider2.com/llama\",\n",
    "    \"Provider3\": \"https://api.provider3.com/llama\"\n",
    "}\n",
    "\n",
    "# Define the prompt to be used for comparison\n",
    "prompt = \"Once upon a time, in a land far, far away, there was a...\"\n",
    "\n",
    "# Function to get response from a provider\n",
    "def get_response(provider_url, prompt):\n",
    "    response = requests.post(provider_url, json={\"prompt\": prompt})\n",
    "    return response.json()\n",
    "\n",
    "# Collect responses from all providers\n",
    "responses = {}\n",
    "for provider, url in providers.items():\n",
    "    responses[provider] = get_response(url, prompt)\n",
    "\n",
    "# Display the responses in a table\n",
    "table = [[provider, response[\"text\"]] for provider, response in responses.items()]\n",
    "display(Markdown(tabulate(table, headers=[\"Provider\", \"Response\"], tablefmt=\"github\")))\n",
    "\n",
    "# Use Weave to evaluate the responses\n",
    "weave.init()\n",
    "evaluation = weave.evaluate_responses(responses)\n",
    "display(Markdown(f\"## Evaluation Results\\n{evaluation}\"))\n"
   ]
  }
 ]
}
