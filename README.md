# compare-llama-providers
This is a quick test to see if all the new LLama 3.1 server providers are returning the same tokens, using Weights & Biases Weave Evaluations [https://wandb.me/weave](https://wandb.me/weave)

## Installation

To get started with this project, you need to install the required dependencies. Follow the steps below:

1. **Create a virtual environment** (optional but recommended):
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

2. **Install the requirements**:
   ```bash
   pip install -r requirements.txt
   ```
